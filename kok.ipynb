{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /home/rikitwiki/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'ultralytics>=8.0.232', 'setuptools>=65.5.1'] not found, attempting AutoUpdate...\n",
      "Collecting gitpython>=3.1.30\n",
      "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
      "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 196.4/196.4 KB 853.1 kB/s eta 0:00:00\n",
      "Collecting ultralytics>=8.0.232\n",
      "  Downloading ultralytics-8.1.11-py3-none-any.whl (709 kB)\n",
      "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 709.5/709.5 KB 3.8 MB/s eta 0:00:00\n",
      "Collecting setuptools>=65.5.1\n",
      "  Downloading setuptools-69.0.3-py3-none-any.whl (819 kB)\n",
      "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 819.5/819.5 KB 12.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.10/site-packages (from gitpython>=3.1.30) (4.0.11)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (4.6.0.66)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (2.31.0)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (5.9.8)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (6.0.1)\n",
      "Requirement already satisfied: py-cpuinfo in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (9.0.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.22.2 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (1.26.2)\n",
      "Requirement already satisfied: thop>=0.1.1 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (0.13.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (10.2.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (1.13.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./venv/lib/python3.10/site-packages (from ultralytics>=8.0.232) (3.8.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30) (5.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics>=8.0.232) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics>=8.0.232) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics>=8.0.232) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics>=8.0.232) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics>=8.0.232) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics>=8.0.232) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics>=8.0.232) (4.48.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics>=8.0.232) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics>=8.0.232) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics>=8.0.232) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics>=8.0.232) (2.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics>=8.0.232) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics>=8.0.232) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics>=8.0.232) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics>=8.0.232) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics>=8.0.232) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics>=8.0.232) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics>=8.0.232) (11.7.99)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->ultralytics>=8.0.232) (0.42.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics>=8.0.232) (1.16.0)\n",
      "Installing collected packages: setuptools, gitpython, ultralytics\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 59.6.0\n",
      "    Uninstalling setuptools-59.6.0:\n",
      "      Successfully uninstalled setuptools-59.6.0\n",
      "  Attempting uninstall: gitpython\n",
      "    Found existing installation: GitPython 3.1.18\n",
      "    Uninstalling GitPython-3.1.18:\n",
      "      Successfully uninstalled GitPython-3.1.18\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.0.229\n",
      "    Uninstalling ultralytics-8.0.229:\n",
      "      Successfully uninstalled ultralytics-8.0.229\n",
      "Successfully installed gitpython-3.1.41 setuptools-69.0.3 ultralytics-8.1.11\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 5.6s, installed 3 packages: ['gitpython>=3.1.30', 'ultralytics>=8.0.232', 'setuptools>=65.5.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelhub-client 1.1.0 requires gitpython<3.1.19, but you have gitpython 3.1.41 which is incompatible.\n",
      "YOLOv5 ğŸš€ 2024-2-10 Python-3.10.12 torch-1.13.1+cu117 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "'Detect' object has no attribute 'grid'. Cache may be out of date, try `force_reload=True` or see https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py:78\u001b[0m, in \u001b[0;36m_create\u001b[0;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[1;32m     77\u001b[0m         LOGGER\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)  \u001b[38;5;66;03m# reset to default\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/GPTI_AutoVision/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:689\u001b[0m, in \u001b[0;36mAutoShape._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    688\u001b[0m m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m=\u001b[39m fn(m\u001b[38;5;241m.\u001b[39mstride)\n\u001b[0;32m--> 689\u001b[0m m\u001b[38;5;241m.\u001b[39mgrid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(fn, \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m))\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m\u001b[38;5;241m.\u001b[39manchor_grid, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/GPTI_AutoVision/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Detect' object has no attribute 'grid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/rikitwiki/Desktop/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43multralytics/yolov5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust this line based on your actual model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Ensure output folder exists\u001b[39;00m\n\u001b[1;32m     15\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/GPTI_AutoVision/venv/lib/python3.10/site-packages/torch/hub.py:542\u001b[0m, in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    539\u001b[0m     repo_or_dir \u001b[38;5;241m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    540\u001b[0m                                        verbose\u001b[38;5;241m=\u001b[39mverbose, skip_validation\u001b[38;5;241m=\u001b[39mskip_validation)\n\u001b[0;32m--> 542\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Desktop/GPTI_AutoVision/venv/lib/python3.10/site-packages/torch/hub.py:572\u001b[0m, in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m hub_module \u001b[38;5;241m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[1;32m    571\u001b[0m entry \u001b[38;5;241m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[0;32m--> 572\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mremove(hubconf_dir)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py:88\u001b[0m, in \u001b[0;36mcustom\u001b[0;34m(path, autoshape, _verbose, device)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom\u001b[39m(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, autoshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# YOLOv5 custom or local model\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py:83\u001b[0m, in \u001b[0;36m_create\u001b[0;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[1;32m     81\u001b[0m help_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Cache may be out of date, try `force_reload=True` or see \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhelp_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for help.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(s) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: 'Detect' object has no attribute 'grid'. Cache may be out of date, try `force_reload=True` or see https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading for help."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define paths\n",
    "input_folder = '/home/rikitwiki/Desktop/gts/'\n",
    "output_folder = '/home/rikitwiki/Desktop/gts_crop_lp/'\n",
    "model_path = '/home/rikitwiki/Desktop/best.pt'\n",
    "\n",
    "# Load model\n",
    "model = torch.hub.load('ultralytics/yolov8', 'custom', path=model_path)  # Adjust this line based on your actual model\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to detect and save license plates\n",
    "def detect_and_save_license_plates(input_folder, output_folder, model):\n",
    "    for img_path in glob.glob(os.path.join(input_folder, '*.jpg')):  # Adjust the extension if needed\n",
    "        # Load image\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        # Detect license plates\n",
    "        results = model(img)\n",
    "        plates = results.pandas().xyxy[0]  # Extract bounding boxes for detected objects\n",
    "        \n",
    "        # Iterate through detected license plates\n",
    "        for i, plate in plates.iterrows():\n",
    "            # Crop license plate\n",
    "            cropped_plate = img.crop((plate['xmin'], plate['ymin'], plate['xmax'], plate['ymax']))\n",
    "            \n",
    "            # Save cropped license plate\n",
    "            cropped_plate.save(os.path.join(output_folder, f\"plate_{i}_{os.path.basename(img_path)}\"))\n",
    "\n",
    "# Run detection and save\n",
    "detect_and_save_license_plates(input_folder, output_folder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/rikitwiki/Desktop/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Load your custom model\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Process the images\u001b[39;00m\n\u001b[1;32m     45\u001b[0m detect_and_crop(model, input_folder, output_folder)\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_path):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# If you have a specific function or class for your model, use it here to load the model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)  \u001b[38;5;66;03m# This is a simplified example; your model loading might differ\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Function to load the model - Adjust this according to your actual setup\n",
    "def load_model(model_path):\n",
    "    # If you have a specific function or class for your model, use it here to load the model\n",
    "    model = torch.load(model_path)  # This is a simplified example; your model loading might differ\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Function to process images and detect license plates\n",
    "def detect_and_crop(model, input_folder, output_folder):\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through all images in the input folder\n",
    "    for img_path in glob.glob(os.path.join(input_folder, '*.jpg')):  # Adjust the pattern as needed\n",
    "        # Load image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = torch.from_numpy(np.array(img)).permute(2, 0, 1).float().unsqueeze(0)  # Adjust as necessary for your model\n",
    "\n",
    "        # Detect\n",
    "        with torch.no_grad():\n",
    "            results = model(img_tensor)  # Adjust this line based on how your model performs detection\n",
    "        \n",
    "        # Assuming results are in a format that includes bounding boxes: [xmin, ymin, xmax, ymax]\n",
    "        for i, (xmin, ymin, xmax, ymax) in enumerate(results['boxes']):  # Adjust based on your results format\n",
    "            # Crop detected license plate\n",
    "            cropped_plate = img.crop((xmin, ymin, xmax, ymax))\n",
    "            \n",
    "            # Save cropped license plate image\n",
    "            cropped_plate.save(os.path.join(output_folder, f\"plate_{i}_{os.path.basename(img_path)}\"))\n",
    "\n",
    "# Paths\n",
    "input_folder = '/home/rikitwiki/Desktop/gts/'\n",
    "output_folder = '/home/rikitwiki/Desktop/gts_crop_lp/'\n",
    "model_path = '/home/rikitwiki/Desktop/best.pt'\n",
    "\n",
    "# Load your custom model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Process the images\n",
    "detect_and_crop(model, input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
